{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Building a Spam Filter with Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Through our learning thus far, we understand the theory of how to classify messages as spam or non-spam using probability. More specifically, we know how the Naive Bayes algorithm operates to achieve this. Our goal with this dataset is to display that operation here.\n",
    "\n",
    "We are using a dataset put together by Tiago A. Almeida and José María Gómez Hidalgo containing 5,572 SMS messages. We want to \"teach\" the computer how to classify these messages using the Niave Bayes algorithm. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our first order of business is to read in the data and take a look at what we are working with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "sms = pd.read_csv(\"SMSSpamCollection\", sep='\\t',header=None, names=['Label','SMS'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                                SMS\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sms.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5572 entries, 0 to 5571\n",
      "Data columns (total 2 columns):\n",
      "Label    5572 non-null object\n",
      "SMS      5572 non-null object\n",
      "dtypes: object(2)\n",
      "memory usage: 87.1+ KB\n"
     ]
    }
   ],
   "source": [
    "sms.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ham     86.593683\n",
       "spam    13.406317\n",
       "Name: Label, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sms['Label'].value_counts(normalize=True) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that from the entire dataset, we have roughly 13% of messages classified as spam and 87 classified as ham (non-spam)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have taken a look at the data, we can move on to building the spam filter. \n",
    "\n",
    "But before doing that, we need to establish a way to test how well it works. This way, once the spam filter is built we can test how good it is with classifying new messages.\n",
    "\n",
    "So we start with splitting the data into a training set and a test set. \n",
    "We use the training set to \"train\" the computer on how to classify messages.\n",
    "We use the test set to see how good the spam filter is with classifying the new messages. \n",
    "\n",
    "With the data we have, we will use about 80% for the training set (4,458 messages) and the remaining 20% for the test set (1,114 messages).\n",
    "\n",
    "Our goal for the project is to create a spam filter that classifies new messages with an accuracy greater than 80%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sms_rand = sms.sample(frac=1,random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "training_set = sms_rand.sample(frac=0.80,random_state=1,replace=False)\n",
    "test_set = sms_rand.sample(frac=0.20, random_state=1,replace=False)\n",
    "\n",
    "training_set = training_set.reset_index(drop=True)\n",
    "test_set = test_set.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4458, 2)\n",
      "(1114, 2)\n"
     ]
    }
   ],
   "source": [
    "print(training_set.shape)\n",
    "print(test_set.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ham     86.675639\n",
       "spam    13.324361\n",
       "Name: Label, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set['Label'].value_counts(normalize=True)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ham     86.175943\n",
       "spam    13.824057\n",
       "Name: Label, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set['Label'].value_counts(normalize=True)*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far we randomized the dataset and then split it into a training set containing 80% of the data and a test_set containing 20% of the data. \n",
    "Each of the training and test set have a distribution of spam and non-spam (ham) that is comparable to the original dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepping the training set data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next thing we need to do is to use the training set to teach the algorithm to classify new messages.\n",
    "\n",
    "We do this using the Niave Bayes algorithm. The algorithm is based on the number of times a specific word is used in each SMS. So we will need to do some cleaning in order to get the data in the correct format (lower case, no punctuation).\n",
    "\n",
    "We will then replace the SMS column with a series of new columns, each corresponding to a unique word from the vocabulary. Each row will represent a new message and the columns will show the amount of times a specific word is used in the message.\n",
    "\n",
    "Lets first clean the data before we separate columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#We start by removing all the punctuation from the SMS column and making words lower case\n",
    "training_set['SMS'] = training_set['SMS'].str.replace('\\W', ' ')\n",
    "training_set['SMS'] = training_set[\"SMS\"].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>good night my dear   sleepwell amp take care</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>sen told that he is going to join his uncle fi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>thank you baby  i cant wait to taste the real ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>when can ü come out</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>no  thank you  you ve been wonderful</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                                SMS\n",
       "0   ham       good night my dear   sleepwell amp take care\n",
       "1   ham  sen told that he is going to join his uncle fi...\n",
       "2   ham  thank you baby  i cant wait to taste the real ...\n",
       "3   ham                               when can ü come out \n",
       "4   ham               no  thank you  you ve been wonderful"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# We split each SMS into individual words and append the different words into a list\n",
    "vocabulary = []\n",
    "\n",
    "training_set['SMS'] = training_set['SMS'].str.split()\n",
    "for message in training_set['SMS']:\n",
    "    for word in message:\n",
    "        vocabulary.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7712"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We use the set function to remove duplicates from the vocabulary list and convert back into a list\n",
    "vocabulary = list(set(vocabulary))\n",
    "len(vocabulary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finalizing the training set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've created a list containing all of the words used in the messages from the training set, we can use this list to make the data transformation we need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# We start by creating a dictionary where the key is a unique word from the vocabulary list\n",
    "word_counts_per_sms = {unique_word: [0] * len(training_set['SMS']) for unique_word in vocabulary}\n",
    "\n",
    "# Next, we loop over the SMS column and use the enumerate function to get an index and the SMS message\n",
    "# We then add this into the dictionary we just created\n",
    "for index, sms in enumerate(training_set['SMS']):\n",
    "    for word in sms:\n",
    "        word_counts_per_sms[word][index] += 1\n",
    "        \n",
    "# Once the dictionary is filled, we transform it into a dataframe and concatenate it with the dataframe containing the training set        \n",
    "word_counts = pd.DataFrame(word_counts_per_sms)\n",
    "word_counts = pd.concat([training_set,word_counts],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "      <th>000pes</th>\n",
       "      <th>008704050406</th>\n",
       "      <th>0089</th>\n",
       "      <th>0121</th>\n",
       "      <th>01223585236</th>\n",
       "      <th>01223585334</th>\n",
       "      <th>0125698789</th>\n",
       "      <th>...</th>\n",
       "      <th>zoe</th>\n",
       "      <th>zogtorius</th>\n",
       "      <th>zoom</th>\n",
       "      <th>zouk</th>\n",
       "      <th>èn</th>\n",
       "      <th>é</th>\n",
       "      <th>ú1</th>\n",
       "      <th>ü</th>\n",
       "      <th>〨ud</th>\n",
       "      <th>鈥</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 7712 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0  00  000  000pes  008704050406  0089  0121  01223585236  01223585334  \\\n",
       "0  0   0    0       0             0     0     0            0            0   \n",
       "1  0   0    0       0             0     0     0            0            0   \n",
       "2  0   0    0       0             0     0     0            0            0   \n",
       "3  0   0    0       0             0     0     0            0            0   \n",
       "4  0   0    0       0             0     0     0            0            0   \n",
       "\n",
       "   0125698789 ...  zoe  zogtorius  zoom  zouk  èn  é  ú1  ü  〨ud  鈥  \n",
       "0           0 ...    0          0     0     0   0  0   0  0    0  0  \n",
       "1           0 ...    0          0     0     0   0  0   0  0    0  0  \n",
       "2           0 ...    0          0     0     0   0  0   0  0    0  0  \n",
       "3           0 ...    0          0     0     0   0  0   0  1    0  0  \n",
       "4           0 ...    0          0     0     0   0  0   0  0    0  0  \n",
       "\n",
       "[5 rows x 7712 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_counts = pd.DataFrame(word_counts_per_sms)\n",
    "word_counts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "      <th>0</th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "      <th>000pes</th>\n",
       "      <th>008704050406</th>\n",
       "      <th>0089</th>\n",
       "      <th>0121</th>\n",
       "      <th>01223585236</th>\n",
       "      <th>...</th>\n",
       "      <th>zoe</th>\n",
       "      <th>zogtorius</th>\n",
       "      <th>zoom</th>\n",
       "      <th>zouk</th>\n",
       "      <th>èn</th>\n",
       "      <th>é</th>\n",
       "      <th>ú1</th>\n",
       "      <th>ü</th>\n",
       "      <th>〨ud</th>\n",
       "      <th>鈥</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>[good, night, my, dear, sleepwell, amp, take, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>[sen, told, that, he, is, going, to, join, his...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>[thank, you, baby, i, cant, wait, to, taste, t...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>[when, can, ü, come, out]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>[no, thank, you, you, ve, been, wonderful]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 7714 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                                SMS  0  00  000  \\\n",
       "0   ham  [good, night, my, dear, sleepwell, amp, take, ...  0   0    0   \n",
       "1   ham  [sen, told, that, he, is, going, to, join, his...  0   0    0   \n",
       "2   ham  [thank, you, baby, i, cant, wait, to, taste, t...  0   0    0   \n",
       "3   ham                          [when, can, ü, come, out]  0   0    0   \n",
       "4   ham         [no, thank, you, you, ve, been, wonderful]  0   0    0   \n",
       "\n",
       "   000pes  008704050406  0089  0121  01223585236 ...  zoe  zogtorius  zoom  \\\n",
       "0       0             0     0     0            0 ...    0          0     0   \n",
       "1       0             0     0     0            0 ...    0          0     0   \n",
       "2       0             0     0     0            0 ...    0          0     0   \n",
       "3       0             0     0     0            0 ...    0          0     0   \n",
       "4       0             0     0     0            0 ...    0          0     0   \n",
       "\n",
       "   zouk  èn  é  ú1  ü  〨ud  鈥  \n",
       "0     0   0  0   0  0    0  0  \n",
       "1     0   0  0   0  0    0  0  \n",
       "2     0   0  0   0  0    0  0  \n",
       "3     0   0  0   0  1    0  0  \n",
       "4     0   0  0   0  0    0  0  \n",
       "\n",
       "[5 rows x 7714 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set_clean = pd.concat([training_set, word_counts], axis=1)\n",
    "training_set_clean.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the Spam Filter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the data cleaning is done and we have a training set we can work with, we can start creating the spam fiter.\n",
    "\n",
    "In order to use the Naive Bayes algorithm, we need to know:\n",
    "  - The P(wi | Spam) \n",
    "  - The P(wi | Ham(non-spam))\n",
    "So we seek to identify those in our first step.\n",
    "We look to calculate P(spam), P(Ham), Nspam, Nham, and Nvocabulary to find the above values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# We first caluculate P(spam) and P(ham)\n",
    "p_spam = len(training_set_clean[training_set_clean['Label'] == 'spam'])/len(training_set_clean)\n",
    "p_ham = len(training_set_clean[training_set_clean['Label'] == 'ham'])/len(training_set_clean)\n",
    "\n",
    "# Next, we calculate Nspam, Nham, and Nvocabulary\n",
    "spam = training_set_clean[training_set_clean['Label'] == 'spam']\n",
    "ham = training_set_clean[training_set_clean['Label'] == 'ham']\n",
    "\n",
    "# Number of words in the spam messages\n",
    "n_spam = sum(spam['SMS'].apply(len))\n",
    "\n",
    "# Number of words in the non-spam messages\n",
    "n_ham = sum(ham['SMS'].apply(len))\n",
    "\n",
    "# Number of unique words in the training dataset\n",
    "n_vocab = len(vocabulary)\n",
    "\n",
    "# Laplace smoothing variable\n",
    "alpha = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've established the variables involved in calculating P(w|spam) and P(w|ham) we can go ahead and solve for those values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# We first create two dictionaries each containing all of the unique words\n",
    "p_w_spam = {unique_word:0 for unique_word in vocabulary}\n",
    "p_w_ham = {unique_word:0 for unique_word in vocabulary}\n",
    "\n",
    "# Then we isolate the spam and ham messsages in the training set into two different dataframes\n",
    "spam = training_set_clean[training_set_clean['Label'] == 'spam']\n",
    "ham = training_set_clean[training_set_clean['Label'] == 'ham']\n",
    "\n",
    "# For each unique word, we calculate p_w_ham and p_w_spam\n",
    "for word in vocabulary:\n",
    "    n_word_given_spam = spam[word].sum()\n",
    "    p_word_given_spam = ((n_word_given_spam) + alpha) / (n_spam + (alpha*n_vocab))\n",
    "    p_w_spam[word] = p_word_given_spam\n",
    "    \n",
    "    n_word_given_ham = ham[word].sum()\n",
    "    p_word_given_ham = (n_word_given_ham + alpha)/(n_ham + alpha*n_vocab)\n",
    "    p_w_ham[word] = p_word_given_ham"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Our two dictionaries should now be filled with the unique words and the probability that the given word is either spam or ham(non-spam)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Finalizing the Spam Filter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Now that we have all of the constants and parameters that we need, we can construct the spam filter.\n",
    "\n",
    "The spam filter can be understood as a function that:\n",
    "  - Takes in a new input message (wn)\n",
    "  - Calculates P(spam | wn) and P(ham | wn)\n",
    "  - compares the values of P(spam | wn) and P(ham | wn) and:\n",
    "      - If P(ham | wn) > P(spam | wn), classifies the message as ham.\n",
    "      - If P(ham | wn) < P(spam | wn), classifies the message as spam.\n",
    "      - If P(ham | wn) = P(spam | wn), refers to human help."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def classify(message):\n",
    "\n",
    "# We can start by cleaning the input message (just like we did with the training set earlier)\n",
    "\n",
    "    message = re.sub('\\W', ' ',message)\n",
    "    message = message.lower()\n",
    "    message = message.split()\n",
    "    \n",
    "# Then we define p_spam_given message and p_ham_given message using the parameters we found earlier\n",
    "# We can start with a placeholder for the two variables\n",
    "    \n",
    "    p_spam_given_message = p_spam #We just need to add in the second half of the equation\n",
    "    p_ham_given_message = p_ham\n",
    "    \n",
    "# We complete the second half of the equation below\n",
    "# We iterate through the words in the message and for each word, multiply the probability value that the message is spam/ham based on the word (found earlier) \n",
    "    \n",
    "    for word in message:\n",
    "        if word in p_w_spam:\n",
    "            p_spam_given_message *= p_w_spam[word]\n",
    "        if word in p_w_ham:\n",
    "            p_ham_given_message *= p_w_ham[word]\n",
    "            \n",
    "# After identifying the probability values, we can compare them to identify the entire message as spam or ham.\n",
    "    \n",
    "    if p_spam_given_message > p_ham_given_message:\n",
    "        return 'spam'\n",
    "    if p_spam_given_message < p_ham_given_message:\n",
    "        return 'ham'\n",
    "    else:\n",
    "        return 'needs human classification'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ham'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classify(\"Sounds good, Tom, then see u there\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'spam'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classify('WINNER!! This is the secret code to unlock the money: C3421.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trying out the spam filter on the test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a function that returns labels and classifies each SMS message in our data, we can use it on our test set data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Good night my dear.. Sleepwell&amp;amp;Take care</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Sen told that he is going to join his uncle fi...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>Thank you baby! I cant wait to taste the real ...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>When can ü come out?</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>No. Thank you. You've been wonderful</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                                SMS predicted\n",
       "0   ham       Good night my dear.. Sleepwell&amp;Take care       ham\n",
       "1   ham  Sen told that he is going to join his uncle fi...       ham\n",
       "2   ham  Thank you baby! I cant wait to taste the real ...       ham\n",
       "3   ham                               When can ü come out?       ham\n",
       "4   ham               No. Thank you. You've been wonderful       ham"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set['predicted'] = test_set['SMS'].apply(classify)\n",
    "test_set.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can compare the predicted values with the Label values to measure how good our spam filter is with classifying new messages.\n",
    "We use accuracy as the metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct: 1106\n",
      "Incorrect: 8\n",
      "Accuracy: 0.992818671454219\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = len(test_set)\n",
    "\n",
    "# We iterate through the dataframe to determine how many rows have the correct label\n",
    "incorrect = []\n",
    "for index, row in test_set.iterrows():\n",
    "    if row['Label'] == row['predicted']:\n",
    "        correct += 1\n",
    "    else:\n",
    "        incorrect.append(row)\n",
    "        \n",
    "print('Correct:', correct)\n",
    "print('Incorrect:', total - correct)\n",
    "print('Accuracy:', correct/total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that we get an accuracy value of 99.2%, which is higher than anticipated, so our spam filter works very well!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Looking into incorrect data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additionally, We can look at the 8 messages that the filter labeled incorrectly and try to understand why the mislabeling occured."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>ham</td>\n",
       "      <td>Anytime...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>spam</td>\n",
       "      <td>FreeMsg Hey there darling it's been 3 week's n...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>ham</td>\n",
       "      <td>The last thing i ever wanted to do was hurt yo...</td>\n",
       "      <td>needs human classification</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>ham</td>\n",
       "      <td>No calls..messages..missed calls</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>spam</td>\n",
       "      <td>Hello darling how are you today? I would love ...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>467</th>\n",
       "      <td>spam</td>\n",
       "      <td>Not heard from U4 a while. Call me now am here...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>482</th>\n",
       "      <td>spam</td>\n",
       "      <td>Missed call alert. These numbers called but le...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>613</th>\n",
       "      <td>spam</td>\n",
       "      <td>Would you like to see my XXX pics they are so ...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Label                                                SMS  \\\n",
       "96    ham                                         Anytime...   \n",
       "115  spam  FreeMsg Hey there darling it's been 3 week's n...   \n",
       "159   ham  The last thing i ever wanted to do was hurt yo...   \n",
       "413   ham                   No calls..messages..missed calls   \n",
       "415  spam  Hello darling how are you today? I would love ...   \n",
       "467  spam  Not heard from U4 a while. Call me now am here...   \n",
       "482  spam  Missed call alert. These numbers called but le...   \n",
       "613  spam  Would you like to see my XXX pics they are so ...   \n",
       "\n",
       "                      predicted  \n",
       "96                         spam  \n",
       "115                         ham  \n",
       "159  needs human classification  \n",
       "413                        spam  \n",
       "415                         ham  \n",
       "467                         ham  \n",
       "482                         ham  \n",
       "613                         ham  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "incorrect = pd.DataFrame(incorrect)\n",
    "incorrect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "96                                            Anytime...\n",
       "115    FreeMsg Hey there darling it's been 3 week's n...\n",
       "159    The last thing i ever wanted to do was hurt yo...\n",
       "413                     No calls..messages..missed calls\n",
       "415    Hello darling how are you today? I would love ...\n",
       "467    Not heard from U4 a while. Call me now am here...\n",
       "482    Missed call alert. These numbers called but le...\n",
       "613    Would you like to see my XXX pics they are so ...\n",
       "Name: SMS, dtype: object"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "incorrect['SMS']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In looking at the incorrectly labeled data, we see that there are various reasons the filter may have mislabeled the message.\n",
    "  - The filter labeled the message as 'needs human classification' meaning the probabilities between spam and ham were equal. This may have happened because the message itself was very long and many of the words used would be found in both spam and ham messages. \n",
    "  - The message contained an explicit reference or illegal offers. These may have been labeled ham because seperately the words may not seem to be spam since a lot of the words in the message are regular words that are probably frequent in many ham messages, but a few words that aren't point to the explicit nature of the message and highlight the need for the message to be spam. \n",
    "  - The punctuation in the message was not filtered out, which may cause a ham message to be labeled as spam."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As mentioned above, we got an accuracy value of 99.2% on our test set, indicating that our spam filter works very well!\n",
    "\n",
    "A recap of our project:\n",
    "  - We took our dataset of 5572 SMS messages and split it into a test set and a training set.\n",
    "  - We used our training set to identify probabilities that a message was spam or ham (non-spam) based on the words in that message. This was defined by identifying parameters of the Naive Bayes algorithm and then using those parameters to create a dictionary for both spam and ham labels that each contained the amount of times a word was used in a message with that label.\n",
    "  - We then created a function based on these findings that identifies a message as spam or ham based on the probability values that the words in the message appear in either spam or ham messages in our training set data.\n",
    "  - Lastly, we applied this function to our test data and were able to measure the accuracy of our spam filter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
